"""
YOLO v8 Object Detection with WebRTC Streaming
ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ê²°ê³¼ë¥¼ WebRTCë¡œ ì†¡ì¶œ
"""

import asyncio
import json
import cv2
import numpy as np
from ultralytics import YOLO
import websockets
from aiortc import RTCPeerConnection, VideoStreamTrack, RTCSessionDescription, RTCConfiguration, RTCIceServer, MediaStreamTrack
from av import VideoFrame
import time
import logging
import os
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# YOLO ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ê²½ë¡œ ì„¤ì •
os.environ['YOLO_VERBOSE'] = 'False'

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DummyAudioStreamTrack(MediaStreamTrack):
    """ë”ë¯¸ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ (ë¬´ìŒ)"""
    
    kind = "audio"
    
    def __init__(self):
        super().__init__()
        
    async def recv(self):
        """ë¬´ìŒ ì˜¤ë””ì˜¤ í”„ë ˆì„ ìƒì„±"""
        from av import AudioFrame
        import numpy as np
        
        pts, time_base = await self.next_timestamp()
        
        # ë¬´ìŒ í”„ë ˆì„ ìƒì„± (48kHz, 20ms, stereo)
        sample_rate = 48000
        samples = 960  # 20ms at 48kHz
        audio_data = np.zeros((2, samples), dtype=np.int16)
        
        frame = AudioFrame.from_ndarray(audio_data, format="s16", layout="stereo")
        frame.sample_rate = sample_rate
        frame.pts = pts
        frame.time_base = time_base
        
        return frame


class YOLOVideoStreamTrack(VideoStreamTrack):
    """YOLO ì²˜ë¦¬ëœ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ WebRTC íŠ¸ë™ìœ¼ë¡œ ë³€í™˜"""
    
    def __init__(self, camera_index=0):
        super().__init__()
        logger.info(f"ğŸ¥ Initializing YOLO Video Track with camera {camera_index}")
        
        # ì¹´ë©”ë¼ ì—°ê²° ì‹œë„ (0ì´ ì•ˆë˜ë©´ 1 ì‹œë„)
        self.cap = cv2.VideoCapture(camera_index)
        if not self.cap.isOpened():
            logger.warning(f"Camera {camera_index} not found, trying alternative...")
            self.cap = cv2.VideoCapture(1)
        
        if not self.cap.isOpened():
            logger.error("No camera found! Will use black frames.")
        else:
            logger.info("âœ… Camera opened successfully")
        
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        self.cap.set(cv2.CAP_PROP_FPS, 30)
        
        # YOLO ëª¨ë¸ ë¡œë“œ
        logger.info("Loading YOLO model...")
        try:
            # ëª¨ë¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìë™ ë‹¤ìš´ë¡œë“œ
            self.model = YOLO('yolov8n.pt')  # nano ëª¨ë¸ë¡œ ì‹œì‘ (ë¹ ë¥¸ ì²˜ë¦¬)
            logger.info("âœ… YOLO model loaded")
        except Exception as e:
            logger.error(f"Failed to load YOLO model: {e}")
            logger.info("Trying to download model...")
            # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¬ì‹œë„
            from ultralytics import YOLO as YOLODownload
            model = YOLODownload('yolov8n.pt')
            model.export(format='onnx')  # ONNXë¡œ ë³€í™˜í•˜ì—¬ í˜¸í™˜ì„± í–¥ìƒ
            self.model = model
            logger.info("YOLO model loaded with alternative method")
        
        self.frame_count = 0
        logger.info("ğŸ¥ YOLO Video Track initialization complete")
        
    async def recv(self):
        try:
            logger.info("YOLO recv() called - starting frame processing")
            pts, time_base = await self.next_timestamp()
            
            # ì›¹ìº ì—ì„œ í”„ë ˆì„ ì½ê¸°
            ret, frame = self.cap.read()
            logger.info(f"Camera read result: {ret}")
            
            if not ret:
                logger.error("Failed to read frame from camera")
                # ì»¬ëŸ¬ í…ŒìŠ¤íŠ¸ íŒ¨í„´ ìƒì„± (ê²€ì€ í™”ë©´ ëŒ€ì‹ )
                frame = np.zeros((480, 640, 3), dtype=np.uint8)
                # ë¹¨ê°„ìƒ‰ ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
                frame[100:300, 200:400] = [0, 0, 255]  # BGR ë¹¨ê°„ìƒ‰
                # í…ìŠ¤íŠ¸ ì¶”ê°€ (ê°„ë‹¨í•œ í‘œì‹œ)
                frame[50:100, 50:200] = [255, 255, 255]  # í°ìƒ‰ ì‚¬ê°í˜•
                logger.info("Using test pattern instead of black frame")
            else:
                logger.info(f"Camera frame shape: {frame.shape}")
                # YOLO ë””í…ì…˜ ìˆ˜í–‰
                logger.info("Starting YOLO detection...")
                results = self.model(frame, verbose=False)
                logger.info("YOLO detection completed")
                
                # íƒì§€ëœ ê°ì²´ ì •ë³´ ë¡œê·¸
                detections = results[0].boxes
                if detections is not None and len(detections) > 0:
                    logger.info(f"âœ… Detected {len(detections)} objects")
                else:
                    logger.info("No objects detected")
                
                # ê²°ê³¼ë¥¼ í”„ë ˆì„ì— ê·¸ë¦¬ê¸°
                annotated_frame = results[0].plot()
                frame = annotated_frame
                logger.info("Frame annotation completed")
                
                self.frame_count += 1
                if self.frame_count % 10 == 0:  # ë” ìì£¼ ë¡œê·¸
                    logger.info(f"ğŸ“¹ Processed {self.frame_count} frames")
            
            # BGR to RGB ë³€í™˜
            logger.info("Converting BGR to RGB...")
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # VideoFrame ìƒì„±
            logger.info("Creating VideoFrame...")
            video_frame = VideoFrame.from_ndarray(frame_rgb, format="rgb24")
            video_frame.pts = pts
            video_frame.time_base = time_base
            
            logger.info("âœ… VideoFrame created successfully")
            return video_frame
            
        except Exception as e:
            logger.error(f"âŒ Error in YOLO recv(): {e}")
            # ì—ëŸ¬ ì‹œ í…ŒìŠ¤íŠ¸ íŒ¨í„´ ë°˜í™˜
            pts, time_base = await self.next_timestamp()
            frame = np.zeros((480, 640, 3), dtype=np.uint8)
            # ì—ëŸ¬ í‘œì‹œìš© ë…¸ë€ìƒ‰ í™”ë©´
            frame[:] = [0, 255, 255]  # BGR ë…¸ë€ìƒ‰
            frame[200:250, 250:400] = [0, 0, 0]  # ê²€ì€ ì¤„ë¬´ëŠ¬
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            video_frame = VideoFrame.from_ndarray(frame_rgb, format="rgb24")
            video_frame.pts = pts
            video_frame.time_base = time_base
            return video_frame
    
    def __del__(self):
        if hasattr(self, 'cap'):
            self.cap.release()


async def run_sender(server_url=None):
    """WebRTC ì†¡ì¶œ ì‹¤í–‰"""
    if server_url is None:
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„œë²„ ì„¤ì • ì½ê¸°
        server_host = os.environ.get('WEBRTC_SERVER_HOST', 'localhost')
        server_port = os.environ.get('WEBRTC_SERVER_PORT', '3000')
        room_name = os.environ.get('WEBRTC_ROOM_NAME', 'room1')
        server_url = f"ws://{server_host}:{server_port}/ws/{room_name}"
    
    logger.info(f"Connecting to {server_url}")
    
    # WebRTC PeerConnection ìƒì„±
    configuration = RTCConfiguration(iceServers=[
        RTCIceServer(urls=["stun:stun.l.google.com:19302"])
    ])
    pc = RTCPeerConnection(configuration=configuration)
    
    # ì˜¤ë””ì˜¤ ë° ë¹„ë””ì˜¤ íŠ¸ë™ ì¶”ê°€
    audio_track = DummyAudioStreamTrack()
    video_track = YOLOVideoStreamTrack(camera_index=0)
    pc.addTrack(audio_track)
    pc.addTrack(video_track)
    logger.info("ğŸ¥ Audio and Video tracks added to PeerConnection")
    
    # WebSocket ì—°ê²°
    async with websockets.connect(server_url) as ws:
        logger.info("WebSocket connected")
        
        # ICE candidate ì²˜ë¦¬
        @pc.on("icecandidate")
        async def on_icecandidate(candidate):
            if candidate:
                await ws.send(json.dumps({
                    "type": "candidate",
                    "candidate": {
                        "candidate": candidate.candidate,
                        "sdpMLineIndex": candidate.sdpMLineIndex,
                        "sdpMid": candidate.sdpMid
                    }
                }))
        
        # hello ë©”ì‹œì§€ ëŒ€ê¸°
        async def handle_messages():
            async for message in ws:
                data = json.loads(message)
                logger.info(f"Received message: {data}")
                
                if data["type"] == "hello":
                    logger.info("Received hello, creating offer...")
                    # Offer ìƒì„±
                    offer = await pc.createOffer()
                    await pc.setLocalDescription(offer)
                    
                    await ws.send(json.dumps({
                        "type": "offer",
                        "sdp": pc.localDescription.sdp,
                        "sdpType": "offer"
                    }))
                    logger.info("Offer sent")
                    
                elif data["type"] == "answer":
                    logger.info("Received answer")
                    answer = RTCSessionDescription(
                        sdp=data["sdp"],
                        type="answer"
                    )
                    await pc.setRemoteDescription(answer)
                    logger.info("WebRTC connection established")
                    
                elif data["type"] == "candidate":
                    if data.get("candidate"):
                        try:
                            # ICE candidate ì²˜ë¦¬ - ì—¬ëŸ¬ ë°©ë²• ì‹œë„
                            candidate_data = data["candidate"]
                            logger.info(f"Processing ICE candidate: {candidate_data}")
                            # ê°„ë‹¨íˆ íŒ¨ìŠ¤ - ICE candidate ì—†ì´ë„ ì—°ê²° ê°€ëŠ¥
                            logger.info("ICE candidate processing skipped")
                        except Exception as e:
                            logger.warning(f"ICE candidate error (ignored): {e}")
        
        try:
            await handle_messages()
        except KeyboardInterrupt:
            logger.info("Interrupted by user")
        except Exception as e:
            logger.error(f"Error: {e}")
        finally:
            await pc.close()


if __name__ == "__main__":
    print("=== YOLO WebRTC Sender ===")
    print("1. ì¹´ë©”ë¼ ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”")
    print("2. viewer.htmlì„ ë¸Œë¼ìš°ì €ì—ì„œ ì—´ì–´ì£¼ì„¸ìš”")
    print("3. ì´ í”„ë¡œê·¸ë¨ì´ ìë™ìœ¼ë¡œ ì—°ê²°ë©ë‹ˆë‹¤")
    print("Ctrl+Cë¡œ ì¢…ë£Œ")
    print("========================")
    
    try:
        asyncio.run(run_sender())
    except KeyboardInterrupt:
        print("\nShutting down...") 